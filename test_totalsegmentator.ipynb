{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e2e49b-fac3-44ec-b89c-d8c0bafdff4c",
   "metadata": {},
   "source": [
    "# Test `totalsegmentator` usage / evaluation\n",
    "\n",
    "**Requires SimpleITK <= 2.1.0, working with 2.0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b66e27-64e6-4658-9145-5f34d45900b8",
   "metadata": {},
   "source": [
    "## Predictions on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f4746-25ab-4948-91b9-dd49ea4698ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:27:11.716382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 16:27:11.831257: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-02 16:27:11.855172: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset total_segmentator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1203/1203 [00:00<00:00, 1771.29it/s]\n",
      "  0%|                                                                                          | 0/1203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Running on CPU. This can be very slow. The '--fast' option can help to some extend.\n",
      "Predicting part 1 of 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etinfo/users2/qlanglois/.local/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/etinfo/users2/qlanglois/.local/lib/python3.9/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting part 2 of 5 ...\n",
      "Predicting part 3 of 5 ...\n",
      "Predicting part 4 of 5 ...\n",
      "Predicting part 5 of 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                              | 16/1203 [03:36<4:28:03, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Running on CPU. This can be very slow. The '--fast' option can help to some extend.\n",
      "Predicting part 1 of 5 ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "dataset = get_dataset('total_segmentator')\n",
    "\n",
    "models  = ['totalsegmentator_lowres', 'totalsegmentator_fullres']\n",
    "\n",
    "for model in models:\n",
    "    for _, row in tqdm(dataset.iterrows(), total = len(dataset)):\n",
    "        output_file = os.path.join('evaluations', model, 'segmentations', row['images'].split('/')[-2] + '.nii.gz')\n",
    "        if not os.path.exists(output_file):\n",
    "            res = totalsegmentator(\n",
    "                row['images'],\n",
    "                output  = output_file,\n",
    "                ml      = True,\n",
    "                fast    = True if 'lowres' in model else False,\n",
    "                verbose = False,\n",
    "                quiet   = True\n",
    "            )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ecbcd-90a3-40b1-83be-ccb707378c98",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7913655-c545-4c02-950f-d5c694c66c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from utils import plot_utils\n",
    "from utils import load_json, dump_json, plot, plot_multiple, plot_volume\n",
    "from datasets import get_dataset, train_test_split\n",
    "from utils.med_utils import TOTALSEGMENTATOR_LABELS, load_medical_seg, transform_mask\n",
    "\n",
    "tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[1:], 'GPU')\n",
    "\n",
    "models       = ['totalsegmentator_lowres', 'totalsegmentator_fullres']\n",
    "dataset_name = 'total_segmentator'\n",
    "\n",
    "dataset = get_dataset(dataset_name)\n",
    "\n",
    "keep_mask = dataset['segmentation'].apply(lambda f: f.endswith('.npz'))\n",
    "skipped   = dataset[~keep_mask]\n",
    "dataset   = dataset[keep_mask]\n",
    "\n",
    "if isinstance(dataset, dict):\n",
    "    train, valid = dataset['train'], dataset['valid']\n",
    "else:\n",
    "    train, valid = train_test_split(\n",
    "        dataset, train_size = 0.9, shuffle = True, random_state = 10, split_by_unique = True, min_occurence = 0\n",
    "    )\n",
    "    #valid = pd.concat([valid, skipped], axis = 0)\n",
    "    \n",
    "\n",
    "print('Dataset length ({} data skipped, {} ids) :\\n  Train size : {} ({} ids)\\n  Valid size : {} ({} ids)'.format(\n",
    "    len(keep_mask) - np.sum(keep_mask.values), len(dataset['id'].unique()), \n",
    "    len(train), len(train['id'].unique()), len(valid), len(valid['id'].unique())\n",
    "))\n",
    "print('# ids in valid that are also in train : {}'.format(len([id_i for id_i in valid['id'].unique() if id_i in train['id'].values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d4c8b-b4cf-43a3-8f47-2c4d07b0a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred, labels):\n",
    "    y_true = transform_mask(y_true, 'dense', is_one_hot = len(y_true.shape) == 4)\n",
    "    y_pred = transform_mask(y_pred, 'dense', is_one_hot = len(y_pred.shape) == 4)\n",
    "    \n",
    "    if hasattr(y_true, 'numpy'): y_true = y_true.numpy()\n",
    "    if hasattr(y_pred, 'numpy'): y_pred = y_pred.numpy()\n",
    "\n",
    "    cm = multilabel_confusion_matrix(y_true.reshape([-1]), y_pred.reshape([-1]))\n",
    "    return {\n",
    "        label : {\n",
    "            'tp' : cm[i, 1, 1], 'fp' : cm[i, 0, 1], 'fn' : cm[i, 1, 0], 'tn' : cm[i, 0, 0] \n",
    "        } for i, label in enumerate(labels) if i < len(cm)\n",
    "    }\n",
    "\n",
    "def compute_metrics(metrics, metric_name, ids = None):\n",
    "    results = {}\n",
    "    for subj_id, infos in metrics.items():\n",
    "        if ids and subj_id not in ids: continue\n",
    "        for c, cm in infos.items():\n",
    "            if c in (None, 'null'): c = 'background'\n",
    "            results.setdefault(c, []).append(_metrics_methods[metric_name](** cm))\n",
    "    \n",
    "    return {c : [vi for vi in v if vi is not None] for c, v in results.items()}\n",
    "\n",
    "def dice_coeff(tp, fp, fn, tn):\n",
    "    if tp + fn + fp == 0: return None\n",
    "    inter = tp\n",
    "    union = 2 * tp + fp + fn\n",
    "    return 2. * inter / max(1, union)\n",
    "\n",
    "_metrics_methods = {\n",
    "    'dice' : dice_coeff\n",
    "}\n",
    "\n",
    "importlib.reload(plot_utils)\n",
    "\n",
    "samples   = dataset\n",
    "overwrite = False\n",
    "\n",
    "all_results = {}\n",
    "for model in models:\n",
    "    results_file = os.path.join('evaluations', model, 'results.json')\n",
    "    results = load_json(results_file, default = {}) if not overwrite else {}\n",
    "\n",
    "    for idx, row in tqdm(samples.iterrows(), total = len(samples)):\n",
    "        subject = row['images'].split('/')[-2]\n",
    "        if subject in results: continue\n",
    "        \n",
    "        true, _ = load_medical_seg(row['segmentation'], mask_labels = row['label'], mapping = TOTALSEGMENTATOR_LABELS)\n",
    "        pred, _ = load_medical_seg(os.path.join('evaluations', model, 'segmentations', '{}.nii.gz'.format(subject)))\n",
    "        if pred.dtype in (np.float32, np.float64): pred = pred.astype(np.int32)\n",
    "        \n",
    "        #plot_volume(true, strides = 3)\n",
    "        #plot_volume(pred, strides = 3)\n",
    "            \n",
    "        results[subject] = compute_confusion_matrix(true, pred, labels = TOTALSEGMENTATOR_LABELS)\n",
    "        \n",
    "        dump_json(results_file, results, indent = 4)\n",
    "    \n",
    "    all_results[model] = results\n",
    "\n",
    "formatted = {\n",
    "    k : compute_metrics(v, 'dice') for k, v in all_results.items()\n",
    "}\n",
    "\n",
    "formatted = {\n",
    "    '\\n{} (avg : {:.2f} %)'.format(k, np.mean([np.mean(vi) for vi in v.values()])) : {'x' : v}\n",
    "    for k, v in formatted.items()\n",
    "}\n",
    "plot_utils.plot_multiple(\n",
    "    ** formatted,\n",
    "    plot_type = 'boxplot', ncols = 1, x_size = 10, y_size = 15, ytick_rotation = 10, vert = False,\n",
    "    xlabel = 'score', ylabel = 'organ', title = 'Dice score', use_subplots = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832bd61-8dea-49a0-bb99-71c88892954c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
