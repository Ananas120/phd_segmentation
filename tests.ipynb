{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc3c6d6-a0d0-45f6-a13c-33b031981033",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80215eba-6a49-4185-af26-9b3a1a3b74e3",
   "metadata": {},
   "source": [
    "## Test Clustering Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be085920-beb3-4d4e-a74a-287e213cca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 10:45:22.835597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 10:45:22.932492: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-18 10:45:22.956552: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/etinfo/users2/qlanglois/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tf.config.set_visible_devices([tf.config.list_physical_devices('GPU')[0]], 'GPU')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896a2c7f-c3d6-40f9-bb64-fd6cc51999f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copyright (C) 2022 yui-mhcp project's author. All rights reserved.\n",
    "# Licenced under the Affero GPL v3 Licence (the \"Licence\").\n",
    "# you may not use this file except in compliance with the License.\n",
    "# See the \"LICENCE\" file at the root of the directory for the licence information.\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.distance import distance\n",
    "\n",
    "class GE2ESegLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "                 mode = 'softmax',\n",
    "                 distance_metric    = 'cosine',\n",
    "                 \n",
    "                 init_w = 1.,\n",
    "                 init_b = 0.,\n",
    "\n",
    "                 name = 'ge2e_seg_loss',\n",
    "                 \n",
    "                 ** kwargs\n",
    "                ):\n",
    "        assert mode in ('softmax', 'contrast')\n",
    "        \n",
    "        super().__init__(name = name, ** kwargs)\n",
    "        self.mode   = mode\n",
    "        self.distance_metric    = distance_metric\n",
    "        \n",
    "        if mode == 'softmax':\n",
    "            self.loss_fn = self.softmax_loss\n",
    "        else:\n",
    "            self.loss_fn = self.contrast_loss\n",
    "        \n",
    "        self.w = tf.Variable(init_w, trainable = True, dtype = tf.float32, name = 'weight')\n",
    "        self.b = tf.Variable(init_b, trainable = True, dtype = tf.float32, name = 'bias')\n",
    "    \n",
    "    @property\n",
    "    def variables(self):\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    def similarity_matrix(self, mask, embeddings):\n",
    "        embeddings = tf.gather_nd(embeddings, mask.indices[:, :-1])\n",
    "        ids        = tf.cast(mask.indices[:, -1], tf.int32)\n",
    "\n",
    "        centroids, centroid_ids  = compute_centroids(embeddings, ids)\n",
    "\n",
    "        return ids, distance(\n",
    "            embeddings,\n",
    "            centroids,\n",
    "            method  = self.distance_metric,\n",
    "            force_distance  = False,\n",
    "            max_matrix_size = -1,\n",
    "            as_matrix       = True\n",
    "        )\n",
    "    \n",
    "    def softmax_loss(self, idx, similarity_matrix):\n",
    "        similarity_matrix = tf.nn.softmax(similarity_matrix, axis = -1)\n",
    "\n",
    "        return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            idx, similarity_matrix\n",
    "        )\n",
    "    \n",
    "    def contrast_loss(self, idx, similarity_matrix):\n",
    "        target_matrix = tf.one_hot(idx, depth = tf.shape(similarity_matrix)[-1])\n",
    "        return tf.reduce_mean(tf.reshape(tf.keras.losses.binary_crossentropy(\n",
    "            tf.reshape(target_matrix, [-1, 1]), tf.sigmoid(tf.reshape(similarity_matrix, [-1, 1]))\n",
    "        ), [-1, tf.shape(similarity_matrix)[-1]]), axis = -1)\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        ids, similarity_matrix = self.similarity_matrix(y_true, y_pred)\n",
    "\n",
    "        return self.loss_fn(ids, cos_sim_matrix)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'mode'  : self.mode,\n",
    "            'init_w'    : self.w.value().numpy(),\n",
    "            'init_b'    : self.b.value().numpy(),\n",
    "            'distance_metric'   : self.distance_metric\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15863be6-32ce-4339-90b0-361e9ae8ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2]\n",
      "tf.Tensor(\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 1 0]\n",
      "  [0 0 1]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 1]\n",
      "  [0 1 0]\n",
      "  [0 1 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 1]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], shape=(4, 4, 3), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe6301545e0>) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mreorder(mask)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mto_dense(mask))\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mto_dense(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe6301545e0>) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "mask = tf.sparse.SparseTensor(\n",
    "    indices = [\n",
    "        [1, 1, 1],\n",
    "        [2, 1, 1],\n",
    "        [2, 2, 1],\n",
    "        [1, 2, 2],\n",
    "        [2, 0, 2],\n",
    "        [3, 1, 2]\n",
    "    ],\n",
    "    values = [1] * 6,\n",
    "    dense_shape = (4, 4, 3)\n",
    ")\n",
    "embeddings = np.zeros((4, 4, 2))\n",
    "for i, j in mask.indices[:, :2].numpy(): embeddings[i, j] = [i, j]\n",
    "embeddings = tf.cast(embeddings, tf.float32)\n",
    "\n",
    "from utils import compute_centroids\n",
    "\n",
    "def distance_matrix(mask, embeddings):\n",
    "    embeddings = tf.gather_nd(embeddings, mask.indices[:, :-1])\n",
    "    ids        = tf.cast(mask.indices[:, -1], tf.int32)\n",
    "    \n",
    "    tf.print(tf.shape(embeddings))\n",
    "    \n",
    "    centroid_ids, centroids  = compute_centroids(embeddings, ids)\n",
    "    \n",
    "    return embeddings, ids, centroids, centroid_ids\n",
    "\n",
    "distance_matrix(mask, embeddings)\n",
    "\n",
    "mask = tf.sparse.reorder(mask)\n",
    "print(tf.sparse.to_dense(mask))\n",
    "print(tf.sparse.to_dense(tf.cast(1, mask.dtype) - mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827969b-38be-4e31-bd9e-741526454052",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f163e4c-479f-4ca2-97f4-5acfd1bfadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 09:47:15.169956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 09:47:15.265040: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-17 09:47:15.289095: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/etinfo/users2/qlanglois/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape : () - mask shape : (1, 249, 188, 213, 104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 09:47:25.299098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 09:47:25.670536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14783 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:17:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from custom_train_objects.losses import dice_loss\n",
    "from utils.med_utils import load_medical_image, load_medical_seg\n",
    "\n",
    "try:\n",
    "    tf.config.set_visible_devices([tf.config.list_physical_devices('GPU')[0]], 'GPU')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "path  = '/storage/Totalsegmentator_dataset/s0001'\n",
    "\n",
    "#image = tf.expand_dims(load_medical_image(os.path.join(path, 'ct.nii.gz'))[0], axis = 0)\n",
    "mask  = tf.sparse.expand_dims(load_medical_seg(os.path.join(path, 'masks.npz'))[0], axis = 0)\n",
    "\n",
    "print('Image shape : {} - mask shape : {}'.format((), mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a8dff-d5ff-4a93-ba7f-9712e7bdd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dice_loss)\n",
    "\n",
    "loss = dice_loss.DiceLoss(skip_empty_frames = False, skip_empty_labels = True, smoothing = 0.01)\n",
    "\n",
    "dense_mask = tf.sparse.to_dense(tf.cast(mask, tf.float32))\n",
    "\n",
    "empty_labels = tf.sparse.reduce_sum(tf.sparse.reshape(mask, [1, -1, 104]), axis = 1) == 0\n",
    "empty_labels = tf.cast(tf.reshape(empty_labels, [1, 1, 1, 1, 104]), tf.float32)\n",
    "\n",
    "print(empty_labels)\n",
    "\n",
    "print(loss(mask, dense_mask).numpy())\n",
    "print(loss(mask, dense_mask * 0.5).numpy())\n",
    "print(loss(mask, dense_mask + 0.25 * empty_labels).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fb9fc-e661-40d0-b66f-c633dc13f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loss(mask, dense_mask + 0.25 * empty_labels)\n",
    "%timeit loss(dense_mask, dense_mask + 0.25 * empty_labels)\n",
    "%timeit loss(tf.sparse.to_dense(mask), dense_mask + 0.25 * empty_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b48a72-7578-40f6-87c1-873bbe0da4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
