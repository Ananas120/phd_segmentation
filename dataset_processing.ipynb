{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a28903-9383-4975-bc61-bdfa96f3fec6",
   "metadata": {},
   "source": [
    "# Dataset pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44951281-a606-4cb5-8b29-a2b0fb7d4b53",
   "metadata": {},
   "source": [
    "## TotalSegmentator dataset normalization (mask combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad81c6d-0891-422e-ae01-5ab12ebc7d46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etinfo/users2/qlanglois/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-04-07 08:30:33.497925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 08:30:34.660120: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-07 08:30:35.180813: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset total_segmentator...\n",
      "Patient 1 / 1204\n",
      "Patient 2 / 1204\n",
      "Patient 3 / 1204\n",
      "Patient 4 / 1204\n",
      "Patient 5 / 1204\n",
      "Patient 6 / 1204\n",
      "Patient 7 / 1204\n",
      "Patient 8 / 1204\n",
      "Patient 9 / 1204\n",
      "Patient 10 / 1204\n",
      "Patient 11 / 1204\n",
      "Patient 12 / 1204\n",
      "Patient 13 / 1204\n",
      "Patient 14 / 1204\n",
      "Patient 15 / 1204\n",
      "Patient 16 / 1204\n",
      "Patient 17 / 1204\n",
      "Patient 18 / 1204\n",
      "Patient 19 / 1204\n",
      "Patient 20 / 1204\n",
      "Patient 21 / 1204\n",
      "Patient 22 / 1204\n",
      "Patient 23 / 1204\n",
      "Patient 24 / 1204\n",
      "Patient 25 / 1204\n",
      "Patient 26 / 1204\n",
      "Patient 27 / 1204\n",
      "Patient 28 / 1204\n",
      "Patient 29 / 1204\n",
      "Patient 30 / 1204\n",
      "Patient 31 / 1204\n",
      "Patient 32 / 1204\n",
      "Patient 33 / 1204\n",
      "Patient 34 / 1204\n",
      "Patient 35 / 1204\n",
      "Patient 36 / 1204\n",
      "Patient 37 / 1204\n",
      "Patient 38 / 1204\n",
      "Patient 39 / 1204\n",
      "Patient 40 / 1204\n",
      "Patient 41 / 1204\n",
      "Patient 42 / 1204\n",
      "Patient 43 / 1204\n",
      "Patient 44 / 1204\n",
      "Patient 45 / 1204\n",
      "Patient 46 / 1204\n",
      "Patient 47 / 1204\n",
      "Patient 48 / 1204\n",
      "Patient 49 / 1204\n",
      "Patient 50 / 1204\n",
      "Patient 51 / 1204\n",
      "Patient 52 / 1204\n",
      "Patient 53 / 1204\n",
      "Patient 54 / 1204\n",
      "Patient 55 / 1204\n",
      "Patient 56 / 1204\n",
      "Patient 57 / 1204\n",
      "Patient 58 / 1204\n",
      "Patient 59 / 1204\n",
      "Patient 60 / 1204\n",
      "Patient 61 / 1204\n",
      "Patient 62 / 1204\n",
      "Patient 63 / 1204\n",
      "Patient 64 / 1204\n",
      "Patient 65 / 1204\n",
      "Patient 66 / 1204\n",
      "Patient 67 / 1204\n",
      "Patient 68 / 1204\n",
      "Patient 69 / 1204\n",
      "Patient 70 / 1204\n",
      "Patient 71 / 1204\n",
      "Patient 72 / 1204\n",
      "Patient 73 / 1204\n",
      "Patient 74 / 1204\n",
      "Patient 75 / 1204\n",
      "Patient 76 / 1204\n",
      "Patient 77 / 1204\n",
      "Patient 78 / 1204\n",
      "Patient 79 / 1204\n",
      "Patient 80 / 1204\n",
      "Patient 81 / 1204\n",
      "Patient 82 / 1204\n",
      "Patient 83 / 1204\n",
      "Patient 84 / 1204\n",
      "Patient 85 / 1204\n",
      "Patient 86 / 1204\n",
      "Patient 87 / 1204\n",
      "Patient 88 / 1204\n",
      "Patient 89 / 1204\n",
      "Patient 90 / 1204\n",
      "Patient 91 / 1204\n",
      "Patient 92 / 1204\n",
      "Patient 93 / 1204\n",
      "Patient 94 / 1204\n",
      "Patient 95 / 1204\n",
      "Patient 96 / 1204\n",
      "Patient 97 / 1204\n",
      "Patient 98 / 1204\n",
      "Patient 99 / 1204\n",
      "Patient 100 / 1204\n",
      "Patient 101 / 1204\n",
      "Patient 102 / 1204\n",
      "Patient 103 / 1204\n",
      "Patient 104 / 1204\n",
      "Patient 105 / 1204\n",
      "Patient 106 / 1204\n",
      "Patient 107 / 1204\n",
      "Patient 108 / 1204\n",
      "Patient 109 / 1204\n",
      "Patient 110 / 1204\n",
      "Patient 111 / 1204\n",
      "Patient 112 / 1204\n",
      "Patient 113 / 1204\n",
      "Patient 114 / 1204\n",
      "Patient 115 / 1204\n",
      "Patient 116 / 1204\n",
      "Patient 117 / 1204\n",
      "Patient 118 / 1204\n",
      "Patient 119 / 1204\n",
      "Patient 120 / 1204\n",
      "Patient 121 / 1204\n",
      "Patient 122 / 1204\n",
      "Patient 123 / 1204\n",
      "Patient 124 / 1204\n",
      "Patient 125 / 1204\n",
      "Patient 126 / 1204\n",
      "Patient 127 / 1204\n",
      "Patient 128 / 1204\n",
      "Patient 129 / 1204\n",
      "Patient 130 / 1204\n",
      "Patient 131 / 1204\n",
      "Patient 132 / 1204\n",
      "Patient 133 / 1204\n",
      "Patient 134 / 1204\n",
      "Patient 135 / 1204\n",
      "Patient 136 / 1204\n",
      "Patient 137 / 1204\n",
      "Patient 138 / 1204\n",
      "Patient 139 / 1204\n",
      "Patient 140 / 1204\n",
      "Patient 141 / 1204\n",
      "Patient 142 / 1204\n",
      "Patient 143 / 1204\n",
      "Patient 144 / 1204\n",
      "Patient 145 / 1204\n",
      "Patient 146 / 1204\n",
      "Patient 147 / 1204\n",
      "Patient 148 / 1204\n",
      "Patient 149 / 1204\n",
      "Patient 150 / 1204\n",
      "Patient 151 / 1204\n",
      "Patient 152 / 1204\n",
      "Patient 153 / 1204\n",
      "Patient 154 / 1204\n",
      "Patient 155 / 1204\n",
      "Patient 156 / 1204\n",
      "Patient 157 / 1204\n",
      "Patient 158 / 1204\n",
      "Patient 159 / 1204\n",
      "Patient 160 / 1204\n",
      "Patient 161 / 1204\n",
      "Patient 162 / 1204\n",
      "Patient 163 / 1204\n",
      "Patient 164 / 1204\n",
      "Patient 165 / 1204\n",
      "Patient 166 / 1204\n",
      "Patient 167 / 1204\n",
      "Patient 168 / 1204\n",
      "Patient 169 / 1204\n",
      "Patient 170 / 1204\n",
      "Patient 171 / 1204\n",
      "Patient 172 / 1204\n",
      "Patient 173 / 1204\n",
      "Patient 174 / 1204\n",
      "Patient 175 / 1204\n",
      "Patient 176 / 1204\n",
      "Patient 177 / 1204\n",
      "Patient 178 / 1204\n",
      "Patient 179 / 1204\n",
      "Patient 180 / 1204\n",
      "Patient 181 / 1204\n",
      "Patient 182 / 1204\n",
      "Patient 183 / 1204\n",
      "Patient 184 / 1204\n",
      "Patient 185 / 1204\n",
      "Patient 186 / 1204\n",
      "Patient 187 / 1204\n",
      "Patient 188 / 1204\n",
      "Patient 189 / 1204\n",
      "Patient 190 / 1204\n",
      "Patient 191 / 1204\n",
      "Patient 192 / 1204\n",
      "Patient 193 / 1204\n",
      "Patient 194 / 1204\n",
      "Patient 195 / 1204\n",
      "Patient 196 / 1204\n",
      "Patient 197 / 1204\n",
      "Patient 198 / 1204\n",
      "Patient 199 / 1204\n",
      "Patient 200 / 1204\n",
      "Patient 201 / 1204\n",
      "Patient 202 / 1204\n",
      "Patient 203 / 1204\n",
      "Patient 204 / 1204\n",
      "Patient 205 / 1204\n",
      "Patient 206 / 1204\n",
      "Patient 207 / 1204\n",
      "Patient 208 / 1204\n",
      "Patient 209 / 1204\n",
      "Patient 210 / 1204\n",
      "Patient 211 / 1204\n",
      "Patient 212 / 1204\n",
      "Patient 213 / 1204\n",
      "Patient 214 / 1204\n",
      "Patient 215 / 1204\n",
      "Patient 216 / 1204\n",
      "Patient 217 / 1204\n",
      "Patient 218 / 1204\n",
      "Patient 219 / 1204\n",
      "Patient 220 / 1204\n",
      "Patient 221 / 1204\n",
      "Patient 222 / 1204\n",
      "Patient 223 / 1204\n",
      "Patient 224 / 1204\n",
      "Patient 225 / 1204\n",
      "Patient 226 / 1204\n",
      "Patient 227 / 1204\n",
      "Patient 228 / 1204\n",
      "Patient 229 / 1204\n",
      "Patient 230 / 1204\n",
      "Patient 231 / 1204\n",
      "Patient 232 / 1204\n",
      "Patient 233 / 1204\n",
      "Patient 234 / 1204\n",
      "Patient 235 / 1204\n",
      "Patient 236 / 1204\n",
      "Patient 237 / 1204\n",
      "Patient 238 / 1204\n",
      "Patient 239 / 1204\n",
      "Patient 240 / 1204\n",
      "Patient 241 / 1204\n",
      "Patient 242 / 1204\n",
      "Patient 243 / 1204\n",
      "Patient 244 / 1204\n",
      "Patient 245 / 1204\n",
      "Patient 246 / 1204\n",
      "Patient 247 / 1204\n",
      "Patient 248 / 1204\n",
      "Patient 249 / 1204\n",
      "Patient 250 / 1204\n",
      "Patient 251 / 1204\n",
      "Patient 252 / 1204\n",
      "Patient 253 / 1204\n",
      "Patient 254 / 1204\n",
      "Patient 255 / 1204\n",
      "Patient 256 / 1204\n",
      "Patient 257 / 1204\n",
      "Patient 258 / 1204\n",
      "Patient 259 / 1204\n",
      "Patient 260 / 1204\n",
      "Patient 261 / 1204\n",
      "Patient 262 / 1204\n",
      "Patient 263 / 1204\n",
      "Patient 264 / 1204\n",
      "Patient 265 / 1204\n",
      "Patient 266 / 1204\n",
      "Patient 267 / 1204\n",
      "Patient 268 / 1204\n",
      "Patient 269 / 1204\n",
      "Patient 270 / 1204\n",
      "Patient 271 / 1204\n",
      "Patient 272 / 1204\n",
      "Patient 273 / 1204\n",
      "Patient 274 / 1204\n",
      "Patient 275 / 1204\n",
      "Patient 276 / 1204\n",
      "Patient 277 / 1204\n",
      "Patient 278 / 1204\n",
      "Patient 279 / 1204\n",
      "Patient 280 / 1204\n",
      "Patient 281 / 1204\n",
      "Patient 282 / 1204\n",
      "Patient 283 / 1204\n",
      "Patient 284 / 1204\n",
      "Patient 285 / 1204\n",
      "Patient 286 / 1204\n",
      "Patient 287 / 1204\n",
      "Patient 288 / 1204\n",
      "Patient 289 / 1204\n",
      "Patient 290 / 1204\n",
      "Patient 291 / 1204\n",
      "Patient 292 / 1204\n",
      "Patient 293 / 1204\n",
      "Patient 294 / 1204\n",
      "Patient 295 / 1204\n",
      "Patient 296 / 1204\n",
      "Patient 297 / 1204\n",
      "Patient 298 / 1204\n",
      "Patient 299 / 1204\n",
      "Patient 300 / 1204\n",
      "Patient 301 / 1204\n",
      "Patient 302 / 1204\n",
      "Patient 303 / 1204\n",
      "Patient 304 / 1204\n",
      "Patient 305 / 1204\n",
      "Patient 306 / 1204\n",
      "Patient 307 / 1204\n",
      "Patient 308 / 1204\n",
      "Patient 309 / 1204\n",
      "Patient 310 / 1204\n",
      "Patient 311 / 1204\n",
      "Patient 312 / 1204\n",
      "Patient 313 / 1204\n",
      "Patient 314 / 1204\n",
      "Patient 315 / 1204\n",
      "Patient 316 / 1204\n",
      "Patient 317 / 1204\n",
      "Patient 318 / 1204\n",
      "Patient 319 / 1204\n",
      "Patient 320 / 1204\n",
      "Patient 321 / 1204\n",
      "Patient 322 / 1204\n",
      "Patient 323 / 1204\n",
      "Patient 324 / 1204\n",
      "Patient 325 / 1204\n",
      "Patient 326 / 1204\n",
      "Patient 327 / 1204\n",
      "Patient 328 / 1204\n",
      "Patient 329 / 1204\n",
      "Patient 330 / 1204\n",
      "Patient 331 / 1204\n",
      "Patient 332 / 1204\n",
      "Patient 333 / 1204\n",
      "Patient 334 / 1204\n",
      "Patient 335 / 1204\n",
      "Patient 336 / 1204\n",
      "Patient 337 / 1204\n",
      "Patient 338 / 1204\n",
      "Patient 339 / 1204\n",
      "Patient 340 / 1204\n",
      "Patient 341 / 1204\n",
      "Patient 342 / 1204\n",
      "Patient 343 / 1204\n",
      "Patient 344 / 1204\n",
      "Patient 345 / 1204\n",
      "Patient 346 / 1204\n",
      "Patient 347 / 1204\n",
      "Patient 348 / 1204\n",
      "Patient 349 / 1204\n",
      "Patient 350 / 1204\n",
      "Patient 351 / 1204\n",
      "Patient 352 / 1204\n",
      "Patient 353 / 1204\n",
      "Patient 354 / 1204\n",
      "Patient 355 / 1204\n",
      "Patient 356 / 1204\n",
      "Patient 357 / 1204\n",
      "Patient 358 / 1204\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import get_dataset\n",
    "from utils.med_utils import load_medical_seg\n",
    "\n",
    "def combine_masks(masks, labels, out_file, overwrite = False, check = False):\n",
    "    if os.path.exists(out_file):\n",
    "        if not overwrite:\n",
    "            if not check: return True\n",
    "            try:\n",
    "                if 'nii' in out_file:\n",
    "                    file = nib.load(out_file)\n",
    "                    file.get_fdata()\n",
    "                    file.uncache()\n",
    "                elif out_file.endswith('npz'):\n",
    "                    with np.load(out_file) as file:\n",
    "                        file['mask']\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print('[ERROR] Error when loading file {} : {}'.format(out_file, e))\n",
    "                os.remove(out_file)\n",
    "    \n",
    "    if out_file.endswith('.npz') and os.path.exists(out_file.replace('.npz', '.nii.gz')):\n",
    "        data = nib.load(out_file.replace('.npz', '.nii.gz'))\n",
    "        \n",
    "        comb_mask, affine, headers = data.get_fdata(), data.affine, data.header\n",
    "        print(comb_mask.shape)\n",
    "    elif out_file.endswith('nii.gz') and os.path.exists(out_file[:-3]):\n",
    "        data = nib.load(out_file[:-3])\n",
    "        \n",
    "        comb_mask, affine, headers = data.get_fdata(), data.affine, data.header\n",
    "        segmented = [\n",
    "            label for i, label in enumerate(labels) if np.any(comb_mask[..., i])\n",
    "        ]\n",
    "        os.remove(out_file[:-3])\n",
    "    else:\n",
    "        comb_mask, affine, headers, segmented = None, None, None, []\n",
    "        for i, label in enumerate(tqdm(labels)):\n",
    "            if label not in masks:\n",
    "                print('[WARNING] Label {} is not in masks !'.format(label))\n",
    "                continue\n",
    "\n",
    "            file = nib.load(masks[label])\n",
    "            mask = file.get_fdata()\n",
    "            if comb_mask is None:\n",
    "                comb_mask = np.zeros(mask.shape + (len(labels), ), dtype = np.uint8)\n",
    "                affine, headers = file.affine, file.header\n",
    "\n",
    "            if mask.shape != comb_mask.shape[:-1]:\n",
    "                raise ValueError('Mask of shape {} != reference mask {}'.format(mask.shape, comb_mask.shape))\n",
    "\n",
    "            mask_bool = mask > 0.5\n",
    "            indexes   = np.where(mask)\n",
    "            if np.any(comb_mask[indexes + (i, )] != 0):\n",
    "                raise ValueError('Overlap with label : {} and {}'.format(label, labels[np.max(comb_mask[indexes + (i, )])]))\n",
    "\n",
    "            if np.any(mask_bool):\n",
    "                segmented.append(label)\n",
    "\n",
    "            comb_mask[indexes + (i, )] = 1\n",
    "            assert np.all(comb_mask[..., i] == mask)\n",
    "\n",
    "        if comb_mask is None:\n",
    "            raise RuntimeError('No valid mask !')\n",
    "    \n",
    "    if 'nii' in out_file:\n",
    "        result = nib.Nifti1Image(comb_mask, affine, header = headers, extra = {'labels' : labels, 'present' : segmented})\n",
    "        nib.save(result, out_file)\n",
    "    elif out_file.endswith('.npz'):\n",
    "        np.savez_compressed(\n",
    "            out_file,\n",
    "            mask   = np.stack(np.where(comb_mask), axis = -1),\n",
    "            shape  = np.array(comb_mask.shape),\n",
    "            affine = affine,\n",
    "            pixdim = headers['pixdim']\n",
    "        )\n",
    "    return True\n",
    "\n",
    "dataset = get_dataset('total_segmentator')\n",
    "\n",
    "labels = list(sorted(dataset.loc[0, 'label']))\n",
    "for i, (_, row) in enumerate(dataset.iloc[::1].iterrows()):\n",
    "    print('Patient {} / {}'.format(i + 1, len(dataset)))\n",
    "    \n",
    "    seg_files = row['segmentation'] if isinstance(row['segmentation'], list) else []\n",
    "    out_file = row['images'].replace('ct.nii.gz', 'masks.npz')\n",
    "    \n",
    "    res = combine_masks(\n",
    "        {organ : file for organ, file in zip(row['label'], row['segmentation'])},\n",
    "        labels, out_file = out_file, overwrite = False, check = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d137e8b-3cc7-4291-b859-7ab5538e3234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 958 ms, sys: 909 ms, total: 1.87 s\n",
      "Wall time: 2.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 19:29:35.173483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 19:29:36.726308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14783 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-04-05 19:29:36.727064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14485 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "\n",
    "path_npz = '/storage/Totalsegmentator_dataset/s0110/masks.npz'\n",
    "path_npz = dataset.iloc[7]['segmentation'].replace('.nii.gz', '.npz')\n",
    "path_nii = path_npz.replace('.npz', '.nii.gz')\n",
    "\n",
    "with np.load(path_npz) as data_npz:\n",
    "    indexes = data_npz['mask']\n",
    "    mask_npz = tf.sparse.SparseTensor(\n",
    "        indices = indexes, values = tf.ones((len(indexes), ), dtype = tf.uint8), dense_shape = data_npz['shape']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83725c2-becc-4508-ac14-863e3403496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 3.42 s, total: 13.5 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_nii = nib.load(path_nii)\n",
    "mask_nii = data_nii.get_fdata(caching = 'unchanged').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942109b-0caf-40b2-b232-58627ac0610f",
   "metadata": {},
   "source": [
    "## Dataset extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404e3263-f1fe-4f89-a71d-106505f95cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▏                             | 77685/128830 [04:43<03:20, 254.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Error while loading /storage/Totalsegmentator_dataset/s0864/ct.nii.gz : Compressed file ended before the end-of-stream marker was reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▎                             | 77899/128830 [04:45<04:10, 203.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] when extracting Totalsegmentator_dataset/s0864/ct.nii.gz : Bad CRC-32 for file 'Totalsegmentator_dataset/s0864/ct.nii.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 128830/128830 [08:14<00:00, 260.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import nibabel as nib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = '/storage'\n",
    "zip_filename = '../Totalsegmentator_dataset.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as file:\n",
    "    for name in tqdm(file.namelist()[:]):\n",
    "        filename = os.path.join(path, name)\n",
    "        if name.endswith('/'):\n",
    "            os.makedirs(filename[:-1], exist_ok = True)\n",
    "            continue\n",
    "        elif os.path.exists(filename):\n",
    "            try:\n",
    "                if 'ct' in filename:\n",
    "                    nib.load(filename).get_fdata(caching = 'unchanged')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print('[ERROR] Error while loading {} : {}'.format(filename, e))\n",
    "                os.remove(filename)\n",
    "        \n",
    "        try:\n",
    "            file.extract(name, path = path)\n",
    "        except Exception as e:\n",
    "            print('[ERROR] when extracting {} : {}'.format(name, e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1aaae-bcb4-4104-b619-ac3e21e84755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
